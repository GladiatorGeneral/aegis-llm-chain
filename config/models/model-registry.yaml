# Model registry configuration

# Predefined models
models:
  - id: llama-2-7b
    name: "Llama 2 7B"
    provider: meta
    type: generative
    size: 7B
    architecture: transformer
    capabilities:
      - generation
      - chat
    deployment:
      resource_requirements:
        gpu: 1
        vram: 16GB
        cpu_cores: 4
        memory: 32GB
    security:
      sandboxed: true
      max_tokens: 4096
  
  - id: mistral-7b
    name: "Mistral 7B"
    provider: mistralai
    type: generative
    size: 7B
    capabilities:
      - generation
      - chat
      - reasoning
    deployment:
      resource_requirements:
        gpu: 1
        vram: 16GB
        cpu_cores: 4
        memory: 32GB
  
  - id: gpt-3.5-turbo
    name: "GPT-3.5 Turbo"
    provider: openai
    type: generative
    size: 175B
    capabilities:
      - generation
      - chat
      - reasoning
      - analysis
    deployment:
      type: api
      api_endpoint: https://api.openai.com/v1

# Model sources
sources:
  - name: huggingface
    url: https://huggingface.co
    authentication_required: true
    
  - name: openai
    url: https://api.openai.com
    authentication_required: true
  
  - name: local
    type: filesystem
    path: /app/models

# Default settings
defaults:
  max_tokens: 2048
  temperature: 0.7
  top_p: 0.9
  timeout_seconds: 300
